{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5878aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in c:\\users\\shail\\anaconda3\\lib\\site-packages (0.0.post11)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c57452e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\shail\\anaconda3\\lib\\site-packages (1.23.5)Note: you may need to restart the kernel to use updated packages.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "017ffe01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\shail\\anaconda3\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96b08afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\shail\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: joblib in c:\\users\\shail\\anaconda3\\lib\\site-packages (from nltk) (1.1.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\shail\\anaconda3\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: click in c:\\users\\shail\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\shail\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8db66f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\shail\\anaconda3\\lib\\site-packages (3.7.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from matplotlib) (22.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from matplotlib) (1.23.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip  install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25803ff2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in c:\\users\\shail\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\shail\\anaconda3\\lib\\site-packages (from imblearn) (0.10.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.23.5)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.2.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (2.2.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.1.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.10.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d66a5e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd2984a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ce7f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc2a2ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79dfdb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "import nltk\n",
    "import re, string\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4038758",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d03b95a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a3ead7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                                  content  \\\n",
       "0                                 Get fucking real dude.   \n",
       "1       She is as dirty as they come  and that crook ...   \n",
       "2       why did you fuck it up. I could do it all day...   \n",
       "3       Dude they dont finish enclosing the fucking s...   \n",
       "4       WTF are you talking about Men? No men thats n...   \n",
       "...                                                  ...   \n",
       "19996    I dont. But what is complaining about it goi...   \n",
       "19997   Bahah  yeah i&;m totally just gonna&; get pis...   \n",
       "19998       hahahahaha >:) im evil mwahahahahahahahahaha   \n",
       "19999            What&;s something unique about Ohio? :)   \n",
       "20000              Who is the biggest gossiper you know?   \n",
       "\n",
       "                          annotation  extras  \n",
       "0      {'notes': '', 'label': ['1']}     NaN  \n",
       "1      {'notes': '', 'label': ['1']}     NaN  \n",
       "2      {'notes': '', 'label': ['1']}     NaN  \n",
       "3      {'notes': '', 'label': ['1']}     NaN  \n",
       "4      {'notes': '', 'label': ['1']}     NaN  \n",
       "...                              ...     ...  \n",
       "19996  {'notes': '', 'label': ['0']}     NaN  \n",
       "19997  {'notes': '', 'label': ['0']}     NaN  \n",
       "19998  {'notes': '', 'label': ['0']}     NaN  \n",
       "19999  {'notes': '', 'label': ['0']}     NaN  \n",
       "20000  {'notes': '', 'label': ['0']}     NaN  \n",
       "\n",
       "[20001 rows x 3 columns]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('./DataSet/Dataset for Detection of Cyber-Trolls.json', lines= True,orient='columns')\n",
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03bb718f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shail\\AppData\\Local\\Temp\\ipykernel_9692\\1367284056.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.annotation[i] = 1\n",
      "C:\\Users\\shail\\AppData\\Local\\Temp\\ipykernel_9692\\1367284056.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.annotation[i] = 0\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(df)):\n",
    "    if df.annotation[i]['label'][0] == '1':\n",
    "        df.annotation[i] = 1\n",
    "    else:\n",
    "        df.annotation[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0af05181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Get fucking real dude.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>She is as dirty as they come  and that crook ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>why did you fuck it up. I could do it all day...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dude they dont finish enclosing the fucking s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WTF are you talking about Men? No men thats n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>I dont. But what is complaining about it goi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>Bahah  yeah i&amp;;m totally just gonna&amp;; get pis...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>hahahahaha &gt;:) im evil mwahahahahahahahahaha</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>What&amp;;s something unique about Ohio? :)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000</th>\n",
       "      <td>Who is the biggest gossiper you know?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20001 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content annotation\n",
       "0                                 Get fucking real dude.          1\n",
       "1       She is as dirty as they come  and that crook ...          1\n",
       "2       why did you fuck it up. I could do it all day...          1\n",
       "3       Dude they dont finish enclosing the fucking s...          1\n",
       "4       WTF are you talking about Men? No men thats n...          1\n",
       "...                                                  ...        ...\n",
       "19996    I dont. But what is complaining about it goi...          0\n",
       "19997   Bahah  yeah i&;m totally just gonna&; get pis...          0\n",
       "19998       hahahahaha >:) im evil mwahahahahahahahahaha          0\n",
       "19999            What&;s something unique about Ohio? :)          0\n",
       "20000              Who is the biggest gossiper you know?          0\n",
       "\n",
       "[20001 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['extras'],axis = 1,inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c4a2cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20001, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f22c0d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['annotation'].value_counts().sort_index().plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f04b6e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive:  60.89195540222989 %\n",
      "Negative:  39.10804459777012 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Positive: \", df.annotation.value_counts()[0]/len(df.annotation)*100,\"%\")\n",
    "print(\"Negative: \", df.annotation.value_counts()[1]/len(df.annotation)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d68900f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [WinError 10060] A\n",
      "[nltk_data]     connection attempt failed because the connected party\n",
      "[nltk_data]     did not properly respond after a period of time, or\n",
      "[nltk_data]     established connection failed because connected host\n",
      "[nltk_data]     has failed to respond>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation</th>\n",
       "      <th>content_without_puncs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Get fucking real dude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>She dirty come crook Rengel Dems fucking corru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>fuck up I could day too Lets hour Ping later s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Dude dont finish enclosing fucking showers I h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>WTF talking Men No men thats menage thats gay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>0</td>\n",
       "      <td>I dont But complaining going do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>0</td>\n",
       "      <td>Bahah yeah im totally gonna get pissed talking...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>0</td>\n",
       "      <td>hahahahaha  im evil mwahahahahahahahahaha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>0</td>\n",
       "      <td>Whats something unique Ohio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000</th>\n",
       "      <td>0</td>\n",
       "      <td>Who biggest gossiper know</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20001 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      annotation                              content_without_puncs\n",
       "0              1                              Get fucking real dude\n",
       "1              1  She dirty come crook Rengel Dems fucking corru...\n",
       "2              1  fuck up I could day too Lets hour Ping later s...\n",
       "3              1  Dude dont finish enclosing fucking showers I h...\n",
       "4              1      WTF talking Men No men thats menage thats gay\n",
       "...          ...                                                ...\n",
       "19996          0                    I dont But complaining going do\n",
       "19997          0  Bahah yeah im totally gonna get pissed talking...\n",
       "19998          0          hahahahaha  im evil mwahahahahahahahahaha\n",
       "19999          0                       Whats something unique Ohio \n",
       "20000          0                          Who biggest gossiper know\n",
       "\n",
       "[20001 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "\n",
    "def test_re(s):\n",
    "    return regex.sub('', s)\n",
    "\n",
    "df ['content_without_stopwords'] = df['content'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "df ['content_without_puncs'] = df['content_without_stopwords'].apply(lambda x: regex.sub('',x))\n",
    "del df['content_without_stopwords']\n",
    "del df['content']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64f5900c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [WinError 10060] A\n",
      "[nltk_data]     connection attempt failed because the connected party\n",
      "[nltk_data]     did not properly respond after a period of time, or\n",
      "[nltk_data]     established connection failed because connected host\n",
      "[nltk_data]     has failed to respond>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation</th>\n",
       "      <th>content_tokenize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>get fuck real dude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>she dirti come crook rengel dem fuck corrupt ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>fuck up i could day too let hour ping later s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>dude dont finish enclos fuck shower i hate ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>wtf talk men no men that menag that gay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>0</td>\n",
       "      <td>i dont but complain go do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>0</td>\n",
       "      <td>bahah yeah im total gon na get piss talk you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>0</td>\n",
       "      <td>hahahahaha im evil mwahahahahahahahahaha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>0</td>\n",
       "      <td>what someth uniqu ohio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000</th>\n",
       "      <td>0</td>\n",
       "      <td>who biggest gossip know</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20001 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      annotation                                   content_tokenize\n",
       "0              1                                 get fuck real dude\n",
       "1              1   she dirti come crook rengel dem fuck corrupt ...\n",
       "2              1   fuck up i could day too let hour ping later s...\n",
       "3              1   dude dont finish enclos fuck shower i hate ha...\n",
       "4              1            wtf talk men no men that menag that gay\n",
       "...          ...                                                ...\n",
       "19996          0                          i dont but complain go do\n",
       "19997          0   bahah yeah im total gon na get piss talk you ...\n",
       "19998          0           hahahahaha im evil mwahahahahahahahahaha\n",
       "19999          0                             what someth uniqu ohio\n",
       "20000          0                            who biggest gossip know\n",
       "\n",
       "[20001 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter_stemmer = PorterStemmer()\n",
    "nltk.download('punkt')\n",
    "tok_list = []\n",
    "size = df.shape[0]\n",
    "\n",
    "for i in range(size):\n",
    "  word_data = df['content_without_puncs'][i]\n",
    "  nltk_tokens = nltk.word_tokenize(word_data)\n",
    "  final = ''\n",
    "  for w in nltk_tokens:\n",
    "    final = final + ' ' + porter_stemmer.stem(w)\n",
    "  tok_list.append(final)\n",
    "\n",
    "df['content_tokenize'] = tok_list\n",
    "del df['content_without_puncs']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "444f23fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation</th>\n",
       "      <th>content_tokenize</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>get fuck real dude</td>\n",
       "      <td>get fuck real dude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>she dirti come crook rengel dem fuck corrupt ...</td>\n",
       "      <td>she dirti come crook rengel dem fuck corrupt ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>fuck up i could day too let hour ping later s...</td>\n",
       "      <td>fuck up i could day too let hour ping later s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>dude dont finish enclos fuck shower i hate ha...</td>\n",
       "      <td>dude dont finish enclos fuck shower i hate ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>wtf talk men no men that menag that gay</td>\n",
       "      <td>wtf talk men no men that menag that gay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>0</td>\n",
       "      <td>i dont but complain go do</td>\n",
       "      <td>i dont but complain go do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>0</td>\n",
       "      <td>bahah yeah im total gon na get piss talk you ...</td>\n",
       "      <td>bahah yeah im total gon na get piss talk you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>0</td>\n",
       "      <td>hahahahaha im evil mwahahahahahahahahaha</td>\n",
       "      <td>hahahahaha im evil mwahahahahahahahahaha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>0</td>\n",
       "      <td>what someth uniqu ohio</td>\n",
       "      <td>what someth uniqu ohio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000</th>\n",
       "      <td>0</td>\n",
       "      <td>who biggest gossip know</td>\n",
       "      <td>who biggest gossip know</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20001 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      annotation                                   content_tokenize  \\\n",
       "0              1                                 get fuck real dude   \n",
       "1              1   she dirti come crook rengel dem fuck corrupt ...   \n",
       "2              1   fuck up i could day too let hour ping later s...   \n",
       "3              1   dude dont finish enclos fuck shower i hate ha...   \n",
       "4              1            wtf talk men no men that menag that gay   \n",
       "...          ...                                                ...   \n",
       "19996          0                          i dont but complain go do   \n",
       "19997          0   bahah yeah im total gon na get piss talk you ...   \n",
       "19998          0           hahahahaha im evil mwahahahahahahahahaha   \n",
       "19999          0                             what someth uniqu ohio   \n",
       "20000          0                            who biggest gossip know   \n",
       "\n",
       "                                                 content  \n",
       "0                                     get fuck real dude  \n",
       "1       she dirti come crook rengel dem fuck corrupt ...  \n",
       "2       fuck up i could day too let hour ping later s...  \n",
       "3       dude dont finish enclos fuck shower i hate ha...  \n",
       "4                wtf talk men no men that menag that gay  \n",
       "...                                                  ...  \n",
       "19996                          i dont but complain go do  \n",
       "19997   bahah yeah im total gon na get piss talk you ...  \n",
       "19998           hahahahaha im evil mwahahahahahahahahaha  \n",
       "19999                             what someth uniqu ohio  \n",
       "20000                            who biggest gossip know  \n",
       "\n",
       "[20001 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noNums = []\n",
    "for i in range(len(df)):\n",
    "  noNums.append(''.join([i for i in df['content_tokenize'][i] if not i.isdigit()]))\n",
    "\n",
    "df['content'] = noNums\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc45c196",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfIdfVectorizer=TfidfVectorizer(use_idf=True, sublinear_tf=True)\n",
    "tfIdf = tfIdfVectorizer.fit_transform(df.content.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3e172df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20001, 14783)\n"
     ]
    }
   ],
   "source": [
    "print(tfIdf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f764ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         TF-IDF\n",
      "sched  0.413066\n",
      "ping   0.382982\n",
      "later  0.306131\n",
      "write  0.287619\n",
      "book   0.285848\n",
      "hour   0.281449\n",
      "here   0.262648\n",
      "let    0.241995\n",
      "up     0.237401\n",
      "could  0.223151\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.DataFrame(tfIdf[2].T.todense(), index=tfIdfVectorizer.get_feature_names_out(), columns=[\"TF-IDF\"]) #for second entry only(just to check if working)\n",
    "df2 = df2.sort_values('TF-IDF', ascending=False)\n",
    "print (df2.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02e8dca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx = pd.DataFrame(tfIdf.toarray(), columns = tfIdfVectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "081dccd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(vectorizer, tfidf_result):\n",
    "    scores = zip(vectorizer.get_feature_names_out(),\n",
    "                 np.asarray(tfidf_result.sum(axis=0)).ravel())\n",
    "    sorted_scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "    i=0\n",
    "    for item in sorted_scores:\n",
    "        print (\"{0:50} Score: {1}\".format(item[0], item[1]))\n",
    "        i = i+1\n",
    "        if (i > 25):\n",
    "          break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8687407a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hate                                               Score: 533.8157298036014\n",
      "fuck                                               Score: 503.76150769255435\n",
      "damn                                               Score: 482.3875012051478\n",
      "suck                                               Score: 407.37790877127185\n",
      "ass                                                Score: 337.54089621427744\n",
      "that                                               Score: 311.6250930420745\n",
      "lol                                                Score: 298.0085779872157\n",
      "im                                                 Score: 296.0216055277791\n",
      "like                                               Score: 287.8183474868775\n",
      "you                                                Score: 284.7850587424088\n",
      "it                                                 Score: 254.75722294501585\n",
      "get                                                Score: 253.19747902607998\n",
      "what                                               Score: 221.43673623523864\n",
      "know                                               Score: 211.53595900888456\n",
      "would                                              Score: 202.5073882820925\n",
      "bitch                                              Score: 193.08800391463464\n",
      "ye                                                 Score: 182.22364463196365\n",
      "love                                               Score: 181.49014270754344\n",
      "go                                                 Score: 180.2588319545915\n",
      "haha                                               Score: 179.29466045019018\n",
      "think                                              Score: 178.9039058038677\n",
      "one                                                Score: 174.16019276608517\n",
      "do                                                 Score: 160.57524593088053\n",
      "time                                               Score: 160.1100301847739\n",
      "gay                                                Score: 159.5820454915121\n",
      "peopl                                              Score: 151.04499856119287\n"
     ]
    }
   ],
   "source": [
    "display_scores(tfIdfVectorizer, tfIdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72065ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18000, 14783)\n",
      "(18000,)\n",
      "(2001, 14783)\n",
      "(2001,)\n"
     ]
    }
   ],
   "source": [
    "X=tfIdf.toarray()\n",
    "y = np.array(df.annotation.tolist())\n",
    "#Spltting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dfe76527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0     1]\n",
      " [10964  7036]]\n"
     ]
    }
   ],
   "source": [
    "unique_elements, counts_elements = np.unique(y_train, return_counts=True)\n",
    "print(np.asarray((unique_elements, counts_elements)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1e88845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    1]\n",
      " [1215  786]]\n"
     ]
    }
   ],
   "source": [
    "unique_elements, counts_elements = np.unique(y_test, return_counts=True)\n",
    "print(np.asarray((unique_elements, counts_elements)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af471d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "oversample = RandomOverSampler(sampling_strategy='not majority')\n",
    "X_over, y_over = oversample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "639d79bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21928, 14783)\n",
      "(21928,)\n"
     ]
    }
   ],
   "source": [
    "print(X_over.shape)\n",
    "print(y_over.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f0ac519a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0     1]\n",
      " [10964 10964]]\n"
     ]
    }
   ],
   "source": [
    "unique_elements, counts_elements = np.unique(y_over, return_counts=True)\n",
    "print(np.asarray((unique_elements, counts_elements)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d2ae21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStatsFromModel(model):\n",
    "  print(classification_report(y_test, y_pred))\n",
    "  disp = plot_precision_recall_curve(model, X_test, y_test)\n",
    "  disp.ax_.set_title('2-class Precision-Recall curve: '\n",
    "                   'AP={0:0.2f}')\n",
    "  \n",
    "  logit_roc_auc = roc_auc_score(y_test, model.predict(X_test))\n",
    "  fpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(X_test)[:,1])\n",
    "  plt.figure()\n",
    "  plt.plot(fpr, tpr, label='(area = %0.2f)' % logit_roc_auc)\n",
    "  plt.plot([0, 1], [0, 1],'r--')\n",
    "  plt.xlim([0.0, 1.0])\n",
    "  plt.ylim([0.0, 1.05])\n",
    "  plt.xlabel('False Positive Rate')\n",
    "  plt.ylabel('True Positive Rate')\n",
    "  plt.title('Receiver operating characteristic')\n",
    "  plt.legend(loc=\"lower right\")\n",
    "  plt.savefig('Log_ROC')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8afef3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  4.2min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.9295352323838081\n",
      "Confusion Matrix: \n",
      " [[1100  115]\n",
      " [  26  760]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.94      1215\n",
      "           1       0.87      0.97      0.92       786\n",
      "\n",
      "    accuracy                           0.93      2001\n",
      "   macro avg       0.92      0.94      0.93      2001\n",
      "weighted avg       0.93      0.93      0.93      2001\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plot_precision_recall_curve' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScore:\u001b[39m\u001b[38;5;124m\"\u001b[39m, rfcmodel\u001b[38;5;241m.\u001b[39mscore(X_test, y_test))\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfusion Matrix: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, confusion_matrix(y_test, y_pred))\n\u001b[1;32m----> 6\u001b[0m \u001b[43mgetStatsFromModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrfc\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[27], line 3\u001b[0m, in \u001b[0;36mgetStatsFromModel\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetStatsFromModel\u001b[39m(model):\n\u001b[0;32m      2\u001b[0m   \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, y_pred))\n\u001b[1;32m----> 3\u001b[0m   disp \u001b[38;5;241m=\u001b[39m \u001b[43mplot_precision_recall_curve\u001b[49m(model, X_test, y_test)\n\u001b[0;32m      4\u001b[0m   disp\u001b[38;5;241m.\u001b[39max_\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2-class Precision-Recall curve: \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      5\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAP=\u001b[39m\u001b[38;5;132;01m{0:0.2f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m   logit_roc_auc \u001b[38;5;241m=\u001b[39m roc_auc_score(y_test, model\u001b[38;5;241m.\u001b[39mpredict(X_test))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_precision_recall_curve' is not defined"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(verbose=True) \n",
    "rfcmodel = rfc.fit(X_over, y_over)\n",
    "y_pred = rfc.predict(X_test)\n",
    "print (\"Score:\", rfcmodel.score(X_test, y_test))\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, y_pred))\n",
    "getStatsFromModel(rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafed3ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "490fb156d22516f038f3e49757df4c1819e7772d913baad3f594c52ef9ea8b3a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
